{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_lofi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "W73cQGRDezTL",
        "outputId": "d474771e-4fb4-4d47-97ff-066311b97da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! pip install music21"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: music21 in /usr/local/lib/python3.6/dist-packages (5.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pJskl0ffjSf"
      },
      "source": [
        "import glob\n",
        "import pickle\n",
        "import time\n",
        "import gc\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from music21 import converter, note, chord\n",
        "import tensorflow as tf\n",
        "\n",
        "from os import listdir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQfx_V7Eioi6",
        "outputId": "9d7142cc-592e-4ffa-b705-270e34b123a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Sanity check to make sure the lofi files are accessible.\n",
        "# You may need to right click the folder on Google Drive and click `Add shortcut\n",
        "#   to Drive` to make the folder accessible from your own drive, then remount\n",
        "print(listdir('/content/drive/My Drive/RNN_lofi'))\n",
        "\n",
        "# Output should be \n",
        "#   Mounted at /content/drive/\n",
        "#   ['lofi', 'lofi_h5']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n",
            "['lofi_h5', 'lofi', 'allNotes1-old.p', 'allNotes2-old.p', 'allNotes1.p', 'allNotes2.p']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpaKqaOnO6y"
      },
      "source": [
        "## Processing the midi into an notes array (done)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNzDEAgfk9gq",
        "outputId": "e42d1a9d-da58-4639-ef71-c2be8c6cfb6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def midis_to_notes(midi_files: [str], output_filename: str) -> str:\n",
        "    # This list will hold notes and chords from all songs appended together\n",
        "    #   use deque to speedup\n",
        "    allNotes = deque()\n",
        "\n",
        "    print('Starting conversion of {} files'.format(len(midi_files)))\n",
        "\n",
        "    gc.disable() # disable gc to speed up append\n",
        "    prevtime = time.clock()\n",
        "    for i, file in enumerate(midi_files):\n",
        "        #print(i,file)\n",
        "        midi = converter.parse(file)\n",
        "        elements = midi.flat.notes\n",
        "\n",
        "        for elem in elements:\n",
        "            # Notes look like 'F#3'\n",
        "            if isinstance(elem, note.Note):\n",
        "                allNotes.append(elem.pitch.nameWithOctave)\n",
        "            # Chords look like 'C4.E4.G#4'\n",
        "            elif isinstance(elem, chord.Chord):\n",
        "                allNotes.append('.'.join(pitch.nameWithOctave for pitch in elem.pitches))\n",
        "\n",
        "        if (i+1) % 50 == 0:\n",
        "            currtime = time.clock()\n",
        "            print('Finished converting {} files, took {} seconds'.format(i+1, currtime - prevtime))\n",
        "            prevtime = currtime\n",
        "            gc.collect()\n",
        "    gc.enable()\n",
        "\n",
        "    print('Done converting midis to string array of notes and chords with len: {}'.format(len(allNotes)))\n",
        "\n",
        "    # Saving the allNotes list to Google Drive cuz it takes bare time to complete\n",
        "    filepath = '/content/drive/My Drive/RNN_lofi/{}.p'.format(output_filename)\n",
        "    with open(filepath, 'wb') as pickleFile:\n",
        "        pickle.dump(allNotes, pickleFile)\n",
        "    \n",
        "    return filepath\n",
        "\n",
        "fileIterator = glob.glob('/content/drive/My Drive/RNN_lofi/lofi/*.midi')\n",
        "# Looks like the original fileIterator is too big? gets big slow downs around halfway\n",
        "fileIt1 = fileIterator[:len(fileIterator)//2]\n",
        "fileIt2 = fileIterator[len(fileIterator)//2:]\n",
        "\n",
        "filePath1 = midis_to_notes(fileIt1, 'allNotes1')\n",
        "filePath2 = midis_to_notes(fileIt2, 'allNotes2')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting conversion of 285 files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8hVK_3bWz3t"
      },
      "source": [
        "##Processing the notes array into the numpy array format for the NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3awD4ZgLSx_",
        "outputId": "239c0769-b5ee-4e5e-8b71-86c86eef2adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Loading allNotes from file\n",
        "allNotes = []\n",
        "\n",
        "filePath1 = '/content/drive/My Drive/RNN_lofi/allNotes1.p'\n",
        "filePath2 = '/content/drive/My Drive/RNN_lofi/allNotes2.p'\n",
        "\n",
        "with open(filePath1, 'rb') as pickleFile1:\n",
        "    allNotes += pickle.load(pickleFile1)\n",
        "with open(filePath2, 'rb') as pickleFile2:\n",
        "    allNotes += pickle.load(pickleFile2)\n",
        "\n",
        "# Look at 10 previous notes to make a prediction\n",
        "#   We can tune this parameter if needed, based on the length of \n",
        "#   chord progressions\n",
        "seqLength = 10\n",
        "print('Using sequence length of {}'.format(seqLength))\n",
        "\n",
        "pitchSet = sorted(set(allNotes))\n",
        "numPitches = len(pitchSet)\n",
        "# here pitches are either notes or chords\n",
        "#   they are sorted lexicographically, so a chord 'C4.E4' will come after a\n",
        "#   note 'C4'\n",
        "print('Identified {} pitches'.format(numPitches))\n",
        "\n",
        "# Map each note/chord to a number normalized to (0,1)\n",
        "pitchMapping = dict((note, number) for (number, note) in enumerate(pitchSet))\n",
        "\n",
        "networkInput = []\n",
        "networkOutput = []\n",
        "\n",
        "print('Starting sequencing of {} notes'.format(len(allNotes)))\n",
        "for i in range(0, len(allNotes)- seqLength):\n",
        "    sequenceIn = allNotes[i:i+seqLength]\n",
        "    predictionOut = allNotes[i+seqLength]\n",
        "\n",
        "    networkInput.append([pitchMapping[note] for note in sequenceIn])\n",
        "    networkOutput.append(pitchMapping[predictionOut])\n",
        "\n",
        "    if (i+1) % 100000 == 0:\n",
        "        print('Finished making {} sequences'.format(i+1))\n",
        "\n",
        "numSeqs = len(networkInput)\n",
        "# reshape input to match the LSTM layer format\n",
        "networkInput = np.reshape(networkInput, (numSeqs, seqLength, 1))\n",
        "networkInput = networkInput / numPitches\n",
        "\n",
        "networkOutput = np.array(networkOutput)\n",
        "\n",
        "print('Done preparing network input and output')\n",
        "# Now data should be in the desired format for the NN\n",
        "\n",
        "print(networkInput)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using sequence length of 10\n",
            "Identified 42308 pitches\n",
            "Starting sequencing of 1607745 notes\n",
            "Finished making 100000 sequences\n",
            "Finished making 200000 sequences\n",
            "Finished making 300000 sequences\n",
            "Finished making 400000 sequences\n",
            "Finished making 500000 sequences\n",
            "Finished making 600000 sequences\n",
            "Finished making 700000 sequences\n",
            "Finished making 800000 sequences\n",
            "Finished making 900000 sequences\n",
            "Finished making 1000000 sequences\n",
            "Finished making 1100000 sequences\n",
            "Finished making 1200000 sequences\n",
            "Finished making 1300000 sequences\n",
            "Finished making 1400000 sequences\n",
            "Finished making 1500000 sequences\n",
            "Finished making 1600000 sequences\n",
            "Done preparing network input and output\n",
            "[[[0.3081923 ]\n",
            "  [0.67188239]\n",
            "  [0.23120923]\n",
            "  ...\n",
            "  [0.19069679]\n",
            "  [0.34544294]\n",
            "  [0.92124421]]\n",
            "\n",
            " [[0.67188239]\n",
            "  [0.23120923]\n",
            "  [0.95298761]\n",
            "  ...\n",
            "  [0.34544294]\n",
            "  [0.92124421]\n",
            "  [0.3594592 ]]\n",
            "\n",
            " [[0.23120923]\n",
            "  [0.95298761]\n",
            "  [0.46875295]\n",
            "  ...\n",
            "  [0.92124421]\n",
            "  [0.3594592 ]\n",
            "  [0.20218398]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.67188239]\n",
            "  [0.24818001]\n",
            "  [0.67188239]\n",
            "  ...\n",
            "  [0.24818001]\n",
            "  [0.67188239]\n",
            "  [0.24818001]]\n",
            "\n",
            " [[0.24818001]\n",
            "  [0.67188239]\n",
            "  [0.24818001]\n",
            "  ...\n",
            "  [0.67188239]\n",
            "  [0.24818001]\n",
            "  [0.67188239]]\n",
            "\n",
            " [[0.67188239]\n",
            "  [0.24818001]\n",
            "  [0.67188239]\n",
            "  ...\n",
            "  [0.24818001]\n",
            "  [0.67188239]\n",
            "  [0.24818001]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fsw_NOEjoAZ",
        "outputId": "8e715ce7-db24-4efd-c92b-9851c23c9a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(type(networkOutput))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1xWFsCWeikV"
      },
      "source": [
        "# Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXqoXwLreo4W",
        "outputId": "5d181b9a-870e-4091-de88-18e004293b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "# Baseline from: https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5?fbclid=IwAR34r6YILe8VuG56VukdnhoM8GnwQUE7OEz3FofTtEVZwqsLYkBiSl-JGSE\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from numpy import array\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "networkInputSmall = networkInput[:10000]\n",
        "networkOutputSmall = networkOutput[:10000]\n",
        "\n",
        "\n",
        "# Things we need to figure out. Lot of these are probably hyperparameters:\n",
        "# 1. number of internal units for layers.\n",
        "# 2. what is dense and what to do with it\n",
        "# 3. input/output dimensions\n",
        "# 4. for each layer and tool we use, look into the possible arguments and figure out what we need to do with each\n",
        "\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(\n",
        "    512,\n",
        "    input_shape=(networkInputSmall.shape[1], networkInputSmall.shape[2]),\n",
        "    return_sequences=True\n",
        "))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "# Add LSTM layer with 512 internal units. We can define stuff like activation function here too.\n",
        "# Comes built in with the information gating system we talk about in our report according to:\n",
        "# https://towardsdatascience.com/implementation-of-rnn-lstm-and-gru-a4250bf6c090\n",
        "model.add(layers.LSTM(512, return_sequences=True))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.LSTM(512))\n",
        "model.add(layers.Dense(256))\n",
        "model.add(layers.Dropout(0.3))\n",
        "# Add a dense layer with 10 units. A dense layer just means it gets output from all neurons in the previous layer.\n",
        "model.add(layers.Dense(numPitches))\n",
        "model.add(layers.Activation('softmax'))\n",
        "\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "# Prints overview of model.\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
        "\n",
        "\n",
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"    \n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    filepath, monitor='loss', \n",
        "    verbose=1,        \n",
        "    save_best_only=True,        \n",
        "    mode='min'\n",
        ")    \n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "model.fit(networkInputSmall, networkOutputSmall, epochs=1, batch_size=64, callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "modelFilepath = '/content/drive/My Drive/RNN_lofi/trained_model'\n",
        "with open(filepath, 'wb') as pickleFile:\n",
        "  pickle.dump(model, pickleFile)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_36 (LSTM)               (None, 10, 512)           1052672   \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_37 (LSTM)               (None, 10, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 10, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_38 (LSTM)               (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_38 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 42308)             10873156  \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 42308)             0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1)                 42309     \n",
            "=================================================================\n",
            "Total params: 16,297,865\n",
            "Trainable params: 16,297,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "157/157 [==============================] - ETA: 0s - loss: 0.0023\n",
            "Epoch 00001: loss improved from inf to 0.00227, saving model to weights-improvement-01-0.0023-bigger.hdf5\n",
            "157/157 [==============================] - 159s 1s/step - loss: 0.0023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-37183272daa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmodelFilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/RNN_lofi/trained_model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpickleFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m   \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickleFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't pickle _thread.RLock objects"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZvIMdo-n1_-"
      },
      "source": [
        "# Generate Music with Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4utQQSjn7Cy",
        "outputId": "b25a4418-ca06-4d07-bc69-f6454d5525dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from music21 import converter, instrument, note, chord, stream\n",
        "\n",
        "start = np.random.randint(0, len(networkInputSmall)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchSet))\n",
        "pattern = networkInputSmall[start]\n",
        "prediction_output = []\n",
        "\n",
        "# generate 500 notes\n",
        "for note_index in range(100):\n",
        "    prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    prediction_input = prediction_input / float(numPitches)\n",
        "    prediction = model.predict(prediction_input, verbose=1)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_note[index]\n",
        "    prediction_output.append(result)\n",
        "    pattern = np.append(pattern, index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "\n",
        "\n",
        "offset = 0\n",
        "output_notes = []\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in prediction_output:\n",
        "    print(pattern)\n",
        "    # pattern is a chord\n",
        "    if ('.' in pattern[0][0]):\n",
        "        notes_in_chord = pattern[0][0].split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(pattern[0][0])\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 3ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 2ms/step\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n",
            "A0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_output.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}